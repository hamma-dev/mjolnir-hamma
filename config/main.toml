# Shared static system configuration

config_version = 1

[general]
    # The default pipeline to use when running the brokkr status and brokkr monitor commands
    monitoring_pipeline_default = "telemetry"
    # The value to use to designate NA values when data is serialized
    na_marker = "NA"
    # How to format the output filename on the client.
    # Items in {} are replaced with their corresponding value
    output_filename_client = "{output_type}_{system_prefix}_{unit_number:0>3}_{utc_date!s}"
    # The path the client should use when storing output data files
    output_path_client = "~/brokkr/{system_name}"
    # How long to wait for the workers to shut down after sending the command
    worker_shutdown_wait_s = 60

# Configuration for the built-in AutoSSH functionality for remote access and data upload.
[autossh]
    # Hostname of the server to connect to
    server_hostname = "104.131.44.197"
    # Username to use on the server
    server_username = "pi"
    # Base offset to the tunnel port to expose on the server (port = offset + unit_number)
    tunnel_port_offset = 10000

# Lookup table of data queues for inter-pipeline communication via QueueSteps
[queues]
    # Queue for the binary AGS science data packets from the HAMMA2 sensors
    science_data_packets = { maxsize = 128 }
    # Queue for the binary AGS science data headers from the HAMMA2 sensors
    science_data_headers = { maxsize = 1000000 }
    # Queue for processing AGS science data for real time information
    realtime_data_packets = { maxsize = 4 }

# List custom steps or override default preset settings here under the [steps] key
[steps]
    # Step for outputting telemetry data to a standard CSV
    [steps.telemetry_csv_output]
        # Preset for this step, in the format "{device_name}.{input/output/command/etc}.{preset_name}"
        _preset = "builtins.outputs.csv_file"
        # Step name, for use in UI text and log messages
        name = "Telemetry CSV Output"
        # Step-specific settings; here lists the output path and filename kwargs
        output_path = "telemetry"
        filename_kwargs = { output_type = "telemetry" }

    [steps.state_monitor]
        _preset = "state_monitor.outputs.plugin"
        power_delim = 20  # delimiter between normal power and low power
        low_space = 100  # if # of GB is less than this, generate a notification
        method = "slack"  # the method how we're going to send notifications
        slack_channel = "testing"  # the channel in slack the notifications will be posted
        slack_key_file = "/home/pi/.slack"  # The path the slack key file

    # Step to create HAMMA plot
    [steps.hamma_plot]
        _module_path = "hamma_plot"
        _class_name = "HammaPlot"
        _is_plugin = true
        name = "Make HAMMA Plot"
        save_path = '/home/pi/brokkr/hamma'
        min_update_time = 30  # seconds

    # Step to rsync HAMMA plot to server
    [steps.hamma_plot_rsync]
        _preset = "rsync_server.outputs.plugin"
        name = "Rsync HAMMA plot"
        server = "104.131.44.197"  # also in autossh
        local_path = '/home/pi/brokkr/hamma/'
        server_path = '/var/www/hamma.dev/public_html/latest'
        update_time = 120  # seconds
        include = '*.png'
        time_key = 'rsync_time_hamma_plot'

    # Step for outputting decoded headers of AGS science packets as CSV
    [steps.science_csv_output]
        _preset = "builtins.outputs.csv_file"
        name = "Science CSV Output"
        output_path = "headers"
        filename_kwargs = { output_type = "headers" }

    # Step to output the HAMMA2 AGS science data packets to a binary file
    [steps.science_binary_output]
        _preset = "builtins.outputs.binary_file"
        name = "HAMMA AGS Science Data Binary File Output"
        key_name = "science_packet"
        output_path = "{drive_path}/{time:%Y-%m-%d}T{time:%H}"
        filename_template = "{system_prefix}{unit_number}_{time:%Y-%m-%d_%H-%M-%S}-{time_ms:0>3}"
        extension = "bin"
        filename_datavalues = [ "time" ]
        drive_kwargs.drive_glob = "DATA??"
        drive_kwargs.mount_glob = true
        drive_kwargs.fallback_path = "~/brokkr/{system_name}/science"
        drive_kwargs.min_free_gb = 0.1

    # Step to output the HAMMA2 AGS science data packets to a queue
    [steps.science_output_queue]
        _preset = "builtins.outputs.queue"
        _queue_name = "science_data_packets"
        name = "HAMMA2 AGS science data output queue"

    # Step to get the HAMMA2 AGS science data packets from a queue
    [steps.science_input_queue]
        _preset = "builtins.inputs.queue"
        _queue_name = "science_data_packets"
        name = "HAMMA2 AGS science data input queue"

    # Step to get AGS science packet from a queue for real time processing
    [steps.realtime_output_queue]
        _preset = "builtins.outputs.queue"
        _queue_name = "realtime_data_packets"
        name = "HAMMA2 AGS Real Time output queue"

    # Step to put AGS science packet in a queue for real time processing
    [steps.realtime_input_queue]
        _preset = "builtins.inputs.queue"
        _queue_name = "realtime_data_packets"
        name = "HAMMA2 AGS Real Time input queue"

    # Step to output the HAMMA2 AGS science data headers to a queue
    [steps.header_output_queue]
        _preset = "builtins.outputs.queue"
        _queue_name = "science_data_headers"
        name = "HAMMA2 AGS science data header output queue"
        truncate_to_headers = true

    # Step to get the HAMMA2 AGS science data headers from a queue
    [steps.header_input_queue]
        _preset = "builtins.inputs.queue"
        _queue_name = "science_data_headers"
        name = "HAMMA2 AGS science data header input queue"


# List pipelines to run here under the [pipelines] key
[pipelines]
    # Engineering telemetry data from Pi, charge controller and sensor
    [pipelines.telemetry]
        # Custom builder for this pipeline
        _builder = "monitor"
        # Name of this pipeline for UI text and log messages
        name = "Telemetry"
        # Custom settings for this pipeline type: here, the interval in s to run monitoring
        monitor_interval_s = 60
        # Whether to inject NAs when starting, so that jumps in data continuity are apparent
        na_on_start = true
        # Most pipeline builders will need one or more lists of steps.
        # These are either names of steps in the [steps] table, or preset names as above
        monitor_input_steps = [
            "builtins.inputs.current_time",
            "builtins.inputs.run_time",
            "sunsaver_mppt_15l.inputs.ram",
            "hamma2.inputs.ping",
            "hamma2.inputs.hs",
        ]
        monitor_output_steps = [
            "telemetry_csv_output",
            "state_monitor",
        ]

    # AGS science data packets from sensor
    [pipelines.science_ingest]
        _builder = "pipeline"
        name = "HAMMA2 AGS Science Data Ingest"
        input_steps = [
            "hamma2.inputs.science_data",
        ]
        process_steps = [
            "builtins.inputs.current_time",
        ]
        output_steps = [
            "science_output_queue",
            "header_output_queue",
        ]

    # AGS binary science data packet output to local HDDs
    [pipelines.science_disk_write]
        _builder = "pipeline"
        name = "HAMMA2 AGS Science Data Binary File Output"
        input_steps = [
            "science_input_queue",
        ]
        process_steps = [
        ]
        output_steps = [
            "science_binary_output",
            "realtime_output_queue",
        ]

    # Do real time processing of HAMMA data
    [pipelines.realtime]
        _builder = "pipeline"
        _enabled = true
        name = "Real time HAMMA processing"
        input_steps = [
            "realtime_input_queue",
            "builtins.inputs.run_time",
        ]
        process_steps = [
            "hamma_plot",
        ]
        output_steps = [
        ]

    # Run rsync to the HAMMA server
    [pipelines.rsync_hamma_realtime]
        _builder = "pipeline"
        _enabled = true
        period_s = 60
        name = "Rsync HAMMA realtime info to server"
        input_steps = [
            "builtins.inputs.current_time",
        ]
        process_steps = [
        ]
        output_steps = [
            "hamma_plot_rsync",
        ]

    # AGS science data header decode and write
    [pipelines.science_header_decode]
        _builder = "pipeline"
        name = "HAMMA2 AGS Science Data Header Decode and Write"
        input_steps = [
            "header_input_queue",
        ]
        process_steps = [
            "hamma2.inputs.science_header",
        ]
        output_steps = [
            "science_csv_output",
        ]

    # AGS science data header monitoring
    [pipelines.science_header_monitor]
        _enabled = false
        _builder = "pipeline"
        name = "HAMMA2 AGS Science Data Header Monitor"
        input_steps = [
            "hamma2.inputs.science_data",
        ]
        process_steps = [
            "builtins.inputs.current_time",
            "hamma2.inputs.science_header",
        ]
        output_steps = [
            "science_csv_output",
        ]
