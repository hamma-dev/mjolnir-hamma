# Shared static system configuration

config_version = 1

[general]
    # The default pipeline to use when running the brokkr status and brokkr monitor commands
    monitoring_pipeline_default = "telemetry"
    # The value to use to designate NA values when data is serialized
    na_marker = "NA"
    # How to format the output filename on the client.
    # Items in {} are replaced with their corresponding value
    output_filename_client = "{output_type}_{system_prefix}_{unit_number:0>3}_{utc_date!s}"
    # The path the client should use when storing output data files
    output_path_client = "~/brokkr/{system_name}"
    # How long to wait for the workers to shut down after sending the command
    worker_shutdown_wait_s = 60

# Configuration for the built-in AutoSSH functionality for remote access and data upload.
[autossh]
    # Hostname of the server to connect to
    server_hostname = "104.131.44.197"
    # Username to use on the server
    server_username = "pi"
    # Base offset to the tunnel port to expose on the server (port = offset + unit_number)
    tunnel_port_offset = 10000

# Lookup table of data queues for inter-pipeline communication via QueueSteps
[queues]
    # Queue for the binary AGS science data packets from the HAMMA2 sensors
    science_data_packets = { maxsize = 128 }
    # Queue for the binary AGS science data headers from the HAMMA2 sensors
    science_data_headers = { maxsize = 1000000 }

# List custom steps or override default preset settings here under the [steps] key
[steps]
    # Step for outputting telemetry data to a standard CSV
    [steps.telemetry_csv_output]
        # Preset for this step, in the format "{device_name}.{input/output/command/etc}.{preset_name}"
        _preset = "builtins.outputs.csv_file"
        # Step name, for use in UI text and log messages
        name = "Telemetry CSV Output"
        # Step-specific settings; here lists the output path and filename kwargs
        output_path = "telemetry"
        filename_kwargs = { output_type = "telemetry" }

    # Step for outputting decoded headers of AGS science packets as CSV
    [steps.science_csv_output]
        _preset = "builtins.outputs.csv_file"
        name = "Science CSV Output"
        output_path = "headers"
        filename_kwargs = { output_type = "headers" }

    # Step to output the HAMMA2 AGS science data packets to a binary file
    [steps.science_binary_output]
        _preset = "builtins.outputs.binary_file"
        name = "HAMMA AGS Science Data Binary File Output"
        output_path = "{drive_path}"
        filename_template = "{system_prefix}{unit_number}_{utc_date!s}_{utc_time:%H-%M-%S}-{milliseconds:0>3}"
        extension = "bin"
        drive_kwargs.drive_glob = "DATA??"
        drive_kwargs.mount_glob = true
        drive_kwargs.fallback_path = "~/brokkr/{system_name}/science"
        drive_kwargs.min_free_gb = 0.1

    # Step to output the HAMMA2 AGS science data packets to a queue
    [steps.science_output_queue]
        _preset = "builtins.outputs.queue"
        _queue_name = "science_data_packets"
        name = "HAMMA2 AGS science data output queue"

    # Step to get the HAMMA2 AGS science data packets from a queue
    [steps.science_input_queue]
        _preset = "builtins.inputs.queue"
        _queue_name = "science_data_packets"
        name = "HAMMA2 AGS science data input queue"

    # Step to output the HAMMA2 AGS science data headers to a queue
    [steps.header_output_queue]
        _preset = "builtins.outputs.queue"
        _queue_name = "science_data_headers"
        name = "HAMMA2 AGS science data header output queue"

    # Step to get the HAMMA2 AGS science data headers from a queue
    [steps.header_input_queue]
        _preset = "builtins.inputs.queue"
        _queue_name = "science_data_headers"
        name = "HAMMA2 AGS science data header input queue"


# List pipelines to run here under the [pipelines] key
[pipelines]
    # Engineering telemetry data from Pi, charge controller and sensor
    [pipelines.telemetry]
        # Custom builder for this pipeline
        _builder = "monitor"
        # Name of this pipeline for UI text and log messages
        name = "Telemetry"
        # Custom settings for this pipeline type: here, the interval in s to run monitoring
        monitor_interval_s = 60
        # Whether to inject NAs when starting, so that jumps in data continuity are apparent
        na_on_start = true
        # Most pipeline builders will need one or more lists of steps.
        # These are either names of steps in the [steps] table, or preset names as above
        monitor_input_steps = [
            "builtins.inputs.current_time",
            "builtins.inputs.run_time",
            "sunsaver_mppt_15l.inputs.ram",
            "hamma2.inputs.ping",
            "hamma2.inputs.hs",
        ]
        monitor_output_steps = [
            "telemetry_csv_output",
        ]

    # AGS science data packets from sensor
    [pipelines.science_ingest]
        _builder = "pipeline"
        name = "HAMMA2 AGS Science Data Ingest"
        input_steps = [
            "hamma2.inputs.science_data",
        ]
        output_steps = [
            "science_output_queue",
            "header_output_queue",
        ]

    # AGS binary science data packet output to local HDDs
    [pipelines.science_disk_write]
        _builder = "pipeline"
        name = "HAMMA2 AGS Science Data Binary File Output"
        input_steps = [
            "science_input_queue",
        ]
        output_steps = [
            "science_binary_output",
        ]

    # AGS science data header decode and write
    [pipelines.science_header_decode]
        _builder = "pipeline"
        name = "HAMMA2 AGS Science Data Header Decode and Write"
        input_steps = [
            "header_input_queue",
        ]
        process_steps = [
            "hamma2.inputs.science_header",
        ]
        output_steps = [
            "science_csv_output",
        ]

    # AGS science data header monitoring
    [pipelines.science_header_monitor]
        _enabled = false
        _builder = "pipeline"
        name = "HAMMA2 AGS Science Data Header Monitor"
        input_steps = [
            "hamma2.inputs.science_data",
        ]
        process_steps = [
            "hamma2.inputs.science_header",
        ]
        output_steps = [
            "science_csv_output",
        ]
